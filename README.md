# DateScience

## Ⅰ、小组信息：

| 学号      | 姓名   | 邮箱                 | 分工             |
| --------- | ------ | -------------------- | ---------------- |
| 211250010 | 毛树杰 | 2486668027@qq.com    | 数据爬取（组长） |
| 211250009 | 严浩翔 | 1171372127@qq.com    | 数据扩增         |
| 211250138 | 何乐阳 | heleyang0311@163.com | 数据验证         |

## Ⅱ、代码开源地址：

### GitHub仓库

**https://github.com/leyang-he/DateScience.git**

### 模型&源数据：

https://www.aliyundrive.com/s/fZcS2dw994t

[sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 · Hugging Face](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2)

## Ⅲ、研究方法：

### 数据据分析方法：

#### 一、数据爬取：

- **爬虫**从相关政务网站获取原始数据

#### 二、数据扩增：

##### 实现方式：

注册成为百度翻译高级个人开发者，申请并通过了百度翻译通用翻译开发模式，使用个人APPID与密钥组合方式，连接百度翻译API进行文本的双向回译。设计传递模式为txt文本形式，爬虫后经筛选程序导出i.txt(i＝1,2...)文本文件，再通过多种语言的双向回译，导出结果为outputi.txt(i＝1,2...)，后续将进一步优化文本扩展方式，期望实现深度学习文本扩展方式。最后以对应式方法，进行文本扩展有效性的测算与反馈。

- 用**百度翻译API回译** *（已实现）*
- **BERT模型**进行同义词、根据上下文模糊词替换*（实现中）*

#### 三、数据验证：

数据验证方式如下。

##### 编辑距离:

1. **验证方式**:

   ```python
   '''
   计算两个字符串间的编辑距离
   '''
   def editDistance(str1,str2):
       matrix = [[0 for j in range(len(str2))] for i in range(str1)]
       for i in range(len(str1)):
           for j in range(len(str2)):
               x = 1
               if str1[i] != str2[j]:
                   x = 0
               matrix[i][j] = max(matrix[i-1][j] + 1,matrix[i][j-1] + 1,matrix[i-1][j-1] + x)
       return matrix[len(str1) - 1][len(str2) - 1]
   ```

2. **优缺点分析**:

   - 优点：实现简单，执行效率较高
   - 缺点：意义不明确，无法从语意层面处理数据。在文章这样复杂的应用场景下难以效果差。

##### Word2Vec:

1. **验证方式**：

   - 处理数据是中文文本，所以需要对数据进行**分词**，分隔成短文本，更加易于处理。使用python的jieba库。
   - 由前两步得到原始数据和扩增数据，使用**Word2Vec库**计算两个数据的**相似度**验证扩增的有效性

2. **优缺点分析**：

   - **优势**：Word2Vec可以将文本映射到向量，把自然语言中的每一个词，表示成一个统一意义统一维度的短向量。相比文本，向量显然更容易处理，数据科学处理方法丰富。	基于神经网络，强化训练效果。
   - **劣势**：模型训练时间长，模型效果比较依赖语料库的效果，对初始文本量要求大。因此对专有名词处理效果差。内存消耗大，需要存储词向量矩阵。依赖词汇表，对**未登录词(OOV)**处理困难，只能加量训练。

3. **后续改进**：

   - 使用Bert模型进行优化。对准确度和相似度给出更加具体的指标。提升运行速度。

4. **数据集**：

   - 原始数据集：[Wikipedia Zh 中文维基百科](https://zh.m.wikipedia.org/zh-hans/%E8%AF%AD%E6%96%99%E5%BA%93)

   - 加量训练：用爬取的数据和扩增后数据扩展Word2vec模型的词汇表


##### Text2Vec/sentence-transformers:

1. **验证方式**：
   - 读入原始文件`source_files`和扩展后文件`extended_files`。
   - 在句子的尺度上对文章进行分割，去掉标点符号和换行符，结果存入列表
   - 将句子嵌入预训练模型`sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`，得到句子的向量表
   - 运用双总体的假设检验，验证扩展之后的数据和扩展前的数据是否有显著差异。另一种验证方式是计算两个向量的余弦相似度。
   - 计算结果存入`./SourceData/Output`文件夹下
2. **优缺点分析：**
   - **优势**：回避了未登录词的问题，嵌入新的数据时不需要重新训练模型。预训练模型准确度更高，效果比较好。实现了句子的相似度比较，不仅仅局限于单个的词。
   - **劣势：**数据分析比较困难

## Ⅳ、案例分析

我们的研究问题是：如何对政务数据的**文本扩增**及扩增后数据有效性的**验证**。

在我们研究案例中，政务领域的样本数量较少，这就导致了文本匹配任务效果下降，所以考虑对现有数据进行扩充。研究主要流程就是主要是对政务网站数据的爬取后，对数据完成扩增工作，并验证扩增后数据的有效性。

我们认为。政务领域的数据特点比较明显。首先，从数据来源来看，政务领域的数据主要集中在国家和各地的政府网站；从数据内容上看，政务网站信息公开透明，权威性准确性高。因此我们选择直接通过爬虫爬取这些政务网站的数据以便后续处理。

而数据的扩增我们选择了目前较为成熟的回译。这样可以获取大量稳定有效的数据。

关于数据验证的部分，我们在研究中尝试过了许多方法，包括直接比较和机器学习方法。直接比较方法有编辑距离、Python标准库中的SequenceMatcher方法。之后又尝试了深度学习方法如Word2vec和Text2vec。不同方法具体的优劣势分析在上文已经提到，应该根据使用场景灵活选择。









